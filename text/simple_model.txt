単純なモデルで試す

git で展開した tnnrb/ruby/sc.rb が人工ニューロンを試すスクリプトになっています。その中で定義されいる SimpleChain がニューロン数、ニューロン層数可変のネットの鋳型になっています。スクリプトでは SimpleChain を鋳型として "model" というネットのオブジェクトを生成しています。
このネットの中に人工ニューロンがあります。"L = Chainer::Links::Connection::Linear" は全結合層で人工ニューロンと人工ニューロンの間の接続を表しています。それが 5層まで可能になっています。ニューロン層という見方だと入力層も含めて 6層までということになります。
ニューラルネットワークの入力と出力はプログラム的にはそれぞれ実数配列となります。ただその配列にもいろいろな表現方法がり、Ruby の標準配列である場合は xA, yA 行列計算ライブラリ Numo の配列である場合は xN, yN Chainer の Variable オブジェクトである場合は xV, yV という変数名で区別しています。
そしてニューラルネットの学習は
model.learn(xV, yV)
で実行されています。この場合、model が xV という入力を受け取ると yV という値を返すように学習されます。つまりこの場合 yV は教師信号とみることができます。
学習の結果を見るには以下のように forward メソッドを使います。
fV = model.forward(xV)
こうして得た fV と教師信号の yV を比べることにより、ちゃんと学習できたかどうかを見ることができます。
入力も出力も配列ですが、その配列の要素数は次元と考えることができます。そうすると例えば 10次元の入力と 5次元の出力とかなると言葉では理解できてもイメージが難しくなります。
そこでイメージしやすくするために、はじめは出力は 1次元、入力も1次元に限定してみます。すると例えば
y=sin(x)
のような入力値 1次元、出力値 1次元で正解がすぐに計算で求まる関数が利用できます。
プログラムのうち tnnrb/ruby/fnSIN.rb は教師信号として y=sin(x) を出すプログラムとなっています。単純に  y=sin(x) を計算しその x と y の数値データを他のパラメータと共に yaml 形式で標準出力に出すだけのものです。
それでは、tnnrb/ruby/fnSIN.rb  を使ってサインカーブを学習させてみます。
隠れ層に 10本のニューロンを入れ、その後の 1本のニューロンの出力を見ます。この場合、ニューロネットワークのレイアウトは sc.rb の "-g" パラメータの右側で “@-10-1”と指定することでできるようになっています。（左側はファイル名などに任意の文字列を使うための部分となっています。）
学習は繰り返し教師信号を与えることにより行われますが、その繰り返し数（エポック数）は "-e" パラメータで与えます。 "-g"  も "-e"  も sc.rb のパラメータですが、教師信号を生成する部分で一括でパラメータを扱いため fnSIN.rb  の "-o" パラメータに含めて間接的に指定しています。
プログラムが表示する "CHECK RESULT" は教師値とニューラルネットの出力値の似た度合いを表しています。
３つのグラフを比べると学習の繰り返し回数であるエポック数が増えると出力値がどんどん教師値に似ていく状況が見えると思います。

$ ../ruby/fnSIN.rb -m lcheck -o '-g SINe05000@-10-1 -i -e  5000 -p' | ../ruby/sc.rb
CHECK RESULT: 21/129 = 16.3%
<img src="../sample/SINe05000@-10-1.png" />

$ ../ruby/fnSIN.rb -m lcheck -o '-g SINe10000@-10-1 -i -e 10000 -p' | ../ruby/sc.rb
CHECK RESULT: 67/129 = 51.9%
<img src="../sample/SINe10000@-10-1.png" />

$ ../ruby/fnSIN.rb -m lcheck -o '-g SINe20000@-10-1 -i -e 20000 -p' | ../ruby/sc.rb
CHECK RESULT: 129/129 = 100.0%
<img src="../sample/SINe20000@-10-1.png" />


今度はニューラルネットに平面上の縦横に広がるサインカーブを教師値として入れてみます。隠れ層に 10本のニューロン 2 段を入れ、その後の 1本のニューロンの出力を見るようにしています。何本のニューロンが何段必要かというのは今のところ試行錯誤で行っているのが実情です。
この場合、入力は 2次元にマッピングされますので
y = f(x0, x1)
という形になります。

../ruby/fnSINSIN.rb -m lcheck -o '-g SINSIN@-10-10-1 -i -e 20000 -p' | ../ruby/sc.rb
CHECK RESULT: 3248/4225 = 76.9%
<img src="../sample/SINSIN@-10-10-1.png" />


同様に 2次元入力で、円のような図形が再現できるか試してみます。
これは 2本の入力ニューロンですから視覚を再現しているわけではありません。
しかし、多次元の値というのは抽象的には図形と捉えることもできます。
視覚とは関係なく高次元図形を処理していると考えるのはどうでしょうか。
あまり多くはないニューロン数で高次元図形を「模倣」できるのが実感できるでしょうか。

../ruby/fnCYLINDER.rb -m lcheck -o '-g CYLINDER@-16-16-1 -i -e 15000 -p' | ../ruby/sc.rb
CHECK RESULT: 855/1089 = 78.5%
<img src="../sample/CYLINDER@-16-16-1.png" />

